#include <ros/ros.h>
#include <stdio.h>
#include <iostream>
#include <math.h>
#include <raspicam/raspicam_cv.h>
#include "mono-vo/vo_features.h"
#include <sys/time.h>
#include "daq/SixDoF.h"
#include "mono-vo/CameraInfo.h"

using namespace cv;
using namespace std;

#define MIN_NUM_FEAT 1000
#define IMAGE_WIDTH  320
#define IMAGE_HEIGHT 240



int main( int argc, char** argv )
{
	ros::init(argc,argv,"RpiCamera");
	ros::NodeHandle RPiC;
	ros::Publisher CAM = RPiC.advertise<daq::SixDoF>("VO_Info",10);

	raspicam::RaspiCam_Cv RPiCam;

	timespec tic,toc;
	double dt;
  	Mat img_old, img_new, R_f = Mat::eye(3, 3, CV_64F), t_f = Mat::zeros(3,1, CV_64F); //the final rotation and tranlation vectors containing the 
	double m[3][3] = {{473.8, 0, 320/2}, {0, 473.8, 240/2}, {0,0,1}};

	Camera RPiCameraInfo;

	if (argc > 1)
	{
		RPiCameraInfo.ReadCalibrationData(argv[0]);
		RPiCameraInfo.SaveCharacteristics(argv[1]);
	}
	else if (argc == 1)
	{
		RPiCameraInfo.ReadCharacteristics(argv[0]);
	}
	else
	{
		cout << "Couldn't Open Camera Information File, Node will exit" << endl
		return -1;
	}

	Mat E = RPiCameraInfo.IntrinsicParameters;


	vector<Point2f> points_old, points_new;        //vectors to store the coordinates of the feature points

	double scale = 1.00;

	RPiCam.set(CV_CAP_PROP_FRAME_WIDTH,IMAGE_WIDTH);
	RPiCam.set(CV_CAP_PROP_FRAME_HEIGHT,IMAGE_HEIGHT);

	if (!RPiCam.open())
	{
		cerr << "Error encountered while trying to open camera" << endl;
		return -1;
	}


  	RPiCam.grab();
	RPiCam.retrieve(img_old);

  	if ( !img_old.data)
	{
		std::cout<< " --(!) Error reading images " << std::endl;
		return -1;
	}

	cvtColor(img_old, img_old, COLOR_BGR2GRAY);

	featureDetection(img_old, points_old);        //detect features in img_old

	vector<uchar> status;

	while(ros::ok())
	{
		clock_gettime(CLOCK_REALTIME, &tic);
		RPiCam.grab();
		RPiCam.retrieve(img_new);
		cvtColor(img_new,img_new,COLOR_BGR2GRAY);

		featureTracking(img_old,img_new,points_old,points_new, status); //track those features to img_new

		double focal = 473.8;
		cv::Point2d pp(320/2, 240/2);

		//Recovering Pose
		if ((points_new.size() > 5) && (points_old.size() > 5))
		{
			recoverPose(E, points_new, points_old, R, t, focal, pp);

			t_f = t_f + scale*(R_f*t);
			R_f = R*R_f;
		}
		else
		{
			cout << "Number of features went below accepted value" << endl;
		}
		if (points_old.size() < MIN_NUM_FEAT)
		{
	 		featureDetection(img_old, points_old);
			featureTracking(img_old,img_new,points_old,points_new, status);
		}

		img_old = img_new.clone();
		points_old = points_new;
		imshow("Preview",img_old);
		waitKey(1);

		daq::SixDoF R_t;

		R_t.Px    = t_f.at<float>(0);
		R_t.Py    = t_f.at<float>(1);
		R_t.Pz    = t_f.at<float>(2);
		R_t.vx    = t.at<float>(0);
		R_t.vy    = t.at<float>(1);
		R_t.vz    = t.at<float>(2);
		R_t.Yaw   = 0;
		R_t.Pitch = 0;
		R_t.Roll  = 0;
		R_t.q     = 0;
		R_t.p     = 0;
		R_t.r     = 0;

		CAM.publish(R_t);

		clock_gettime(CLOCK_REALTIME, &toc);
		dt = abs((double) toc.tv_nsec - (double) tic.tv_nsec);
		printf("Sample Time is : %f \n",dt/1000000000);
	}
	RPiCam.release();
	return 0;
}
